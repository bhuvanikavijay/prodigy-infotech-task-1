{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8412,
          "sourceType": "datasetVersion",
          "datasetId": 5637
        }
      ],
      "dockerImageVersionId": 30035,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuvanikavijay/prodigy-infotech-task-1/blob/main/prodigy_infotech_task_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'sherlock-holmes-stories:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5637%2F8412%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240813%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240813T061255Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D035690d0d134240aa23dcec8655eb534e01aa28ecb5df1fd23d60a963da039e0cba92f2caf2cd4c9561940f244b241a44da355f28156ae0333c66a01ea8c80ba50c8fb9c7c29e50683df609a75a024d41b2058e2a7e7b9ae9b76cfb612669b08bac395cf088001129eba6cb9b59ff54f2eb23af01992a2e9a7d4a9efbdd6301cbee054b8d0cf82c2e6aed36d446b2b2cdddd083a3f9d2b31c9ab9e90463d64a9629db916b416fff71b406f0ff5c96e7d549d03ce8b09a9444ce02d3b81d015c8073286788033488ef53db28dd902b0a8b5bba9d89cb5f6d36dbb65e40be1a6b81433f934d70effe4957dc8c7ca40816c76963283687552c4e3893e2c5c1eb1e2'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4CD-rSeYEo7",
        "outputId": "ebe9ae7d-bc8b-4ad8-fd6d-1389cf2da7e3"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sherlock-holmes-stories, 10414294 bytes compressed\n",
            "[==================================================] 10414294 bytes downloaded\n",
            "Downloaded and uncompressed: sherlock-holmes-stories\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pOpGBSq_x9UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-08-13T06:09:43.350344Z",
          "iopub.execute_input": "2024-08-13T06:09:43.351334Z",
          "iopub.status.idle": "2024-08-13T06:09:43.374903Z",
          "shell.execute_reply.started": "2024-08-13T06:09:43.351271Z",
          "shell.execute_reply": "2024-08-13T06:09:43.372955Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuGdWVYmYEpB",
        "outputId": "e803fad5-dd09-44bc-c3b9-467d15a38f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story_path = \"/kaggle/input/sherlock-holmes-stories/sherlock/sherlock/\"\n",
        "\n",
        "def read_all_stories(story_path):\n",
        "    txt = []\n",
        "    for _, _, files in os.walk(story_path):\n",
        "        for file in files:\n",
        "            with open(story_path+file) as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line=='----------': break\n",
        "                    if line!='':txt.append(line)\n",
        "    return txt\n",
        "\n",
        "stories = read_all_stories(story_path)\n",
        "print(\"number of lines = \", len(stories))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:09:43.379656Z",
          "iopub.execute_input": "2024-08-13T06:09:43.381933Z",
          "iopub.status.idle": "2024-08-13T06:09:44.081991Z",
          "shell.execute_reply.started": "2024-08-13T06:09:43.381878Z",
          "shell.execute_reply": "2024-08-13T06:09:44.080936Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJpGN8iqYEpC",
        "outputId": "eda9d435-e505-45cd-c93f-18e94ab364f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of lines =  215021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    for line in txt:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_stories = clean_txt(stories)\n",
        "print(\"number of words = \", len(cleaned_stories))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:10:20.475497Z",
          "iopub.execute_input": "2024-08-13T06:10:20.475878Z",
          "iopub.status.idle": "2024-08-13T06:10:47.746718Z",
          "shell.execute_reply.started": "2024-08-13T06:10:20.475841Z",
          "shell.execute_reply": "2024-08-13T06:10:47.745674Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLOLvTznYEpC",
        "outputId": "1665ddf8-1407-4cf3-cc88-b4fdee41fc09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words =  2332247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "\n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "\n",
        "    return markov_model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:11:42.383486Z",
          "iopub.execute_input": "2024-08-13T06:11:42.383921Z",
          "iopub.status.idle": "2024-08-13T06:11:42.397502Z",
          "shell.execute_reply.started": "2024-08-13T06:11:42.383886Z",
          "shell.execute_reply": "2024-08-13T06:11:42.396456Z"
        },
        "trusted": true,
        "id": "614sazhIYEpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = make_markov_model(cleaned_stories)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:11:46.582409Z",
          "iopub.execute_input": "2024-08-13T06:11:46.583069Z",
          "iopub.status.idle": "2024-08-13T06:11:53.79297Z",
          "shell.execute_reply.started": "2024-08-13T06:11:46.58303Z",
          "shell.execute_reply": "2024-08-13T06:11:53.792114Z"
        },
        "trusted": true,
        "id": "hbuXEGcMYEpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of states = \", len(markov_model.keys()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:11:58.541283Z",
          "iopub.execute_input": "2024-08-13T06:11:58.541977Z",
          "iopub.status.idle": "2024-08-13T06:11:58.553488Z",
          "shell.execute_reply.started": "2024-08-13T06:11:58.541918Z",
          "shell.execute_reply": "2024-08-13T06:11:58.552097Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blByQwNDYEpD",
        "outputId": "4822d2d1-2644-41c3-95dc-6e0c861a2b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states =  208716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All possible transitions from 'the game' state: \\n\")\n",
        "print(markov_model['the game'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:12:02.893977Z",
          "iopub.execute_input": "2024-08-13T06:12:02.894353Z",
          "iopub.status.idle": "2024-08-13T06:12:02.900132Z",
          "shell.execute_reply.started": "2024-08-13T06:12:02.894321Z",
          "shell.execute_reply": "2024-08-13T06:12:02.899274Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sySuVvFVYEpE",
        "outputId": "2cc38bac-3286-4fa5-fdf3-40a15866143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All possible transitions from 'the game' state: \n",
            "\n",
            "{'in their': 0.036036036036036036, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'was afoot': 0.036036036036036036, 'your letter': 0.02702702702702703, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'was up': 0.09009009009009009, 'for the': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'would have': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'was whist': 0.036036036036036036, 'is afoot': 0.036036036036036036, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story+=curr_state+\" \"\n",
        "    while n<limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "\n",
        "        curr_state = next_state[0]\n",
        "        story+=curr_state+\" \"\n",
        "        n+=1\n",
        "    return story"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:12:10.10439Z",
          "iopub.execute_input": "2024-08-13T06:12:10.105341Z",
          "iopub.status.idle": "2024-08-13T06:12:10.117648Z",
          "shell.execute_reply.started": "2024-08-13T06:12:10.10529Z",
          "shell.execute_reply": "2024-08-13T06:12:10.11665Z"
        },
        "trusted": true,
        "id": "x-5jJ17YYEpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"dear holmes\", limit=8))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:12:15.957299Z",
          "iopub.execute_input": "2024-08-13T06:12:15.957988Z",
          "iopub.status.idle": "2024-08-13T06:12:15.985639Z",
          "shell.execute_reply.started": "2024-08-13T06:12:15.957947Z",
          "shell.execute_reply": "2024-08-13T06:12:15.984902Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn_TNXiWYEpE",
        "outputId": "82a439ca-26ff-471a-ea1d-9c8352dc7480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  dear holmes i have not been cleared yet sherlock holmes you compel me to say whether the present \n",
            "1.  dear holmes i thought i can not allow yourself to the fact that rodger prescott of evil memory \n",
            "2.  dear holmes i exclaimed and then put up the shutters a man of his sudden and so terrible \n",
            "3.  dear holmes i exclaimed it is perhaps the villain was softened by the womans character did you ask \n",
            "4.  dear holmes i thought as much knowledge of your stepfather why what can it mean who is cadogan \n",
            "5.  dear holmes if i had not been able to bring peace to many troubled souls i trust that \n",
            "6.  dear holmes he has broken the doctor said holmes blandly you have introduced yourselves i can not promise \n",
            "7.  dear holmes if i hadnt sworn not to marry anyone else while he lived without any open scandal \n",
            "8.  dear holmes i thought when he first met garcia but i found my plans very seriously to finding \n",
            "9.  dear holmes said i the two warders had been shot through the dark shrubbery amid the labyrinth of \n",
            "10.  dear holmes i ejaculated surely said i the vampire was not necessarily a guilty reason for it ive \n",
            "11.  dear holmes that i hesitated to jump until i should do for us i should be so careful \n",
            "12.  dear holmes if i pay him well at least he delivers the goods to use his brown face \n",
            "13.  dear holmes if i went oh jack it would be for my dear girl it would be as \n",
            "14.  dear holmes i have inquired at all the central inferences and presents ones audience with the visit to \n",
            "15.  dear holmes i ejaculated no no that was this morning which wants more thinking out than to get \n",
            "16.  dear holmes said i when should i take him i expect him back every minute mcmurdo continued to \n",
            "17.  dear holmes said i that this matter really strikes very much deeper than either you or the girl \n",
            "18.  dear holmes that i must have caused great pain when he had picked up his oh thats it \n",
            "19.  dear holmes i thought nothing of it at mapleton when i told her so that we had sat \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"my dear\", limit=8))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:12:21.217506Z",
          "iopub.execute_input": "2024-08-13T06:12:21.218181Z",
          "iopub.status.idle": "2024-08-13T06:12:21.243766Z",
          "shell.execute_reply.started": "2024-08-13T06:12:21.218141Z",
          "shell.execute_reply": "2024-08-13T06:12:21.242787Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w4zmcr9YEpE",
        "outputId": "ad1489a6-a3bd-4422-ed47-ee8832f798ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  my dear fellow and must lead her a most uneasy life yet i have his letters were to \n",
            "1.  my dear watson there i think that my poor father i have explained sir eustace was a confirmed \n",
            "2.  my dear watson but it is incredible that such a situation it is most important said holmes and \n",
            "3.  my dear sir cried dr mortimer was reading had it all every man and choleric his passion is \n",
            "4.  my dear arthur i found him in deep emotion pray continue i said your telegram was soon followed \n",
            "5.  my dear sir knowing the vindictive character of a free present of interest to do so we have \n",
            "6.  my dear fellow how can you tell me any message for me to cause the frail thread to \n",
            "7.  my dear doctor said he nodding at the instant that a human countenance is capable of stopping it \n",
            "8.  my dear fellow for a german mr von bork you are a smart man and that he would \n",
            "9.  my dear watson said he unquestionably it is really mr holmes said he i shall write two letters \n",
            "10.  my dear fellow be it so chanced that some little nervous disturbance in my waistcoat pocket i was \n",
            "11.  my dear fellow in my way to clearing james mccarthy was acquitted at the garden gate the professor \n",
            "12.  my dear fellow in the matter and have no other dear me staples how often have i said \n",
            "13.  my dear watson with what eagerness i listened to him as it were right that brought old theresa \n",
            "14.  my dear friend stood i know him to the arrangement more than possible it is probable that he \n",
            "15.  my dear arthur i found him seated upon a chest constructed to carry things of great personal beauty \n",
            "16.  my dear arthur i screamed you villain you villain now now at last it is that the murdered \n",
            "17.  my dear daughter alice and spoke to her but got no answer but he must be serious watson \n",
            "18.  my dear holmes said she the maid is still tied to her chamber for an instant holmes had \n",
            "19.  my dear watson but the colonels wife could have taken it across to me years ago a peruvian \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"i would\", limit=8))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:12:29.30002Z",
          "iopub.execute_input": "2024-08-13T06:12:29.300688Z",
          "iopub.status.idle": "2024-08-13T06:12:29.322742Z",
          "shell.execute_reply.started": "2024-08-13T06:12:29.300647Z",
          "shell.execute_reply": "2024-08-13T06:12:29.321954Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQmTtAdYYEpE",
        "outputId": "5f2b7a29-fba6-49c8-de80-d7abe5d84b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  i would send you one of the few days which our start the doctor from interfering and the \n",
            "1.  i would rather die under my companions guidance we made our way into the room i had to \n",
            "2.  i would pay ten that would hardly do he cried i understand it admits that she had passed \n",
            "3.  i would hardly go out at his agony his drawn brows and the granite moulding of the inflexible \n",
            "4.  i would take this chair by the fire i ventured to say and do nothing which aroused your \n",
            "5.  i would spend my life hiking round the world in search of them i get so near him \n",
            "6.  i would have nothing further to say only to ask any questions mr holmes i never even knew \n",
            "7.  i would see her it took all his habitual coolness was in his that any other fact by \n",
            "8.  i would move said the secretary examining the house myself i was aware that you will have to \n",
            "9.  i would do justice upon him and buried his knife but the crash of the lamp was out \n",
            "10.  i would only ask a little help why said my time is seared into my memory has quite \n",
            "11.  i would sooner face a martini bullet myself are you loitering there for there was an exceedingly alert \n",
            "12.  i would put it into his armchair and greeting his visitor with a sudden shivering of his eyelids \n",
            "13.  i would find that he has withdrawn form the window i could have sworn that it was all \n",
            "14.  i would have nothing to do we can imagine that he may well have wished his wife out \n",
            "15.  i would wish to know what mycroft is i had admired treated in this state have bound themselves \n",
            "16.  i would retire to my he always apologized to me that was beside the dead policeman the accused \n",
            "17.  i would not he cried but it has certainly a very interesting affair which at first i was \n",
            "18.  i would not have given me my decrepit italian friend as a minor point it may have nothing \n",
            "19.  i would lay a dark mass which looked out upon his expedition no i cant say that i \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_story(markov_model, start=\"the case\", limit=100))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-13T06:12:33.875017Z",
          "iopub.execute_input": "2024-08-13T06:12:33.875682Z",
          "iopub.status.idle": "2024-08-13T06:12:33.890128Z",
          "shell.execute_reply.started": "2024-08-13T06:12:33.875642Z",
          "shell.execute_reply": "2024-08-13T06:12:33.88918Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uE--P62YEpE",
        "outputId": "7adf5c8f-2dcc-4b54-bb13-90b6060972cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the case is the writing pooh pooh forgery my private room at the union house until it comes back to the time of my readers in the singular old observance called the ragged shaw now watson the fair susan who waited upon us at our hotel holmes tore it open a coat which was found in the boys round before evening to meet in lodge one of these papers they should not rain before we are making a fool of myself he gasped not at all except into the garden gate swung open and shut then came the death of her husband and her blazing eyes bounding after its victim hurl him to the rude was a small turban of the same reason no powder on her nose that proved to be kicked from here to the north of england and cut him over here and there great strips had become detached and hung like an open wound lay low in the same relative position to prove nothing i took the matter a small sliding shutter and plunging in his power i am sure that you were a few footmarks and the terra del fuegians the average height is rather more to \n"
          ]
        }
      ]
    }
  ]
}